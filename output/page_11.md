# Running AI Offline: Requirements 

- Hardware requirements for offline LLMs:
- Small models (e.g. LLaMA 3.2 3B):
- Modern laptops (8GB+ RAM)
- Suitable for basic tasks (summarization, simple Q\&A)
- Medium models (e.g. LLaMA 3.1 70B):
- High-end workstations or servers (64GB+ RAM, GPU acceleration)
- Handle more complex tasks (advanced Q\&A, document analysis)
- Large models (e.g. LLaMA 3.1 405B):
- Specialized AI hardware (e.g. TPUs, clusters with 1TB+ RAM)
- Tackle the most demanding AI applications (complex reasoning, creative generation)